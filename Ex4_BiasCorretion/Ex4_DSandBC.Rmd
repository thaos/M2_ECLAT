---
title: "Exercice 4 : descente d'échelle statistique et correction de bias"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. Execute a chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

## Objectifs
Le but est de présenter le principe de fonctionnement de la descente d'échelle statistique et de la correction. Pour cela, nous appliquerons quelques méthodes de base. Deux sont des méthodes dites de Perfect Prognosis et les deux autres de la catégorie Model Output Statstics.

## Downscalling

### Lecture des données
```{r}
tas_df <- readRDS("../Ex1_whoiswho/Ex1_tas_df.rds")

# Downscaling
X <- tas_df[, "ERA5"]
Y <- tas_df[, "GHCND_orly"]
ina <- is.na(X) | is.na(Y)
X <- X[!ina]
Y <- Y[!ina]
dates <- as.numeric(rownames(tas_df))
dates <- dates[!ina]
```

### Séparation en base d'apprentissage et base de test (calibration/validation)

```{r}
iapp <- dates < 20000101
X_app <- X[iapp]
Y_app <- Y[iapp]
X_test <- X[!iapp]
Y_test <- Y[!iapp]
```


### Comparaison entre X et Y
```{r, fig.width = 6, fig.height = 9}
# Root Mean Square Error (RMSE)
sqrt(mean((Y_app - X_app)^2))
# Correlation
cor(X_app, Y_app)
sqrt(mean((Y_test - X_test)^2))
cor(X_test, Y_test)

# Scatterplots
par(mfrow = c(2, 1), pty = "s")
xylim <- range(X, Y, na.rm = TRUE)
plot(X_app, Y_app, xlim = xylim, ylim = xylim)
abline(b = 1, a = 0, col = "red")
plot(X_test, Y_test, xlim = xylim, ylim = xylim)
abline(b = 1, a = 0, col = "red")

# Différences des séries temporelles
par(mfrow = c(2, 1), pty = "m")
ylim = range(Y_app - X_app, Y_test - X_test)
plot(Y_app - X_app, type = "l", ylim = ylim)
plot(Y_test - X_test, type = "l", ylim = ylim)

# quantile-quantile plot (QQ-plot)
par(mfrow = c(2, 1), pty = "s")
qqplot(X_app, Y_app, xlim = xylim, ylim = xylim, main = "QQ-plot")
abline(b = 1, a = 0, col = "red")
qqplot(X_test, Y_test, xlim = xylim, ylim = xylim, main = "QQ-plot")
abline(b = 1, a = 0, col = "red")
```

### Perfect Prog

#### Linear Model

Utiliser la fonction lm pour ajuster un modèle linéaire pour expliquer Y en fonction de X

Utiliser la fonction *predict* pour appliquer le modèle appris à la base d'apprentissage et de test.

Comparer les prédictions aux vrais valeurs de Y.

Le modèle appris est il aussi sur la base de test que sur la base d'apprentissage ?

```{r, fig.width = 6, fig.height = 9}
base_app <- data.frame(X = X_app, Y = Y_app)
base_test <- data.frame(X = X_test, Y = Y_test)
lm_fit <- lm(, data = ) # à compléter
summary(lm_fit)

lm_app <- predict()  # à compléter
lm_test <- predict()  # à compléter

# RMSE et corrélation entre valeurs prédites et réelles de Y sur base d'apprentissage


# RMSE et corrélation entre valeurs prédites et réelles de Y sur base de test


# diagnostics graphiques sur bases d'apprentissage et de test
par(mfrow = c(2, 1), pty = "s")
plot(lm_app, Y_app, xlim = xylim, ylim = xylim)
abline(b = 1, a = 0, col = "red")
plot(lm_test, Y_test, xlim = xylim, ylim = xylim)
abline(b = 1, a = 0, col = "red")

ylim = range(Y_app - lm_app, Y_test - lm_test)
par(mfrow = c(2, 1), pty = "m")
plot(Y_app - lm_app, type = "l", ylim = ylim)
plot(Y_test - lm_test, type = "l", ylim = ylim)

par(mfrow = c(2, 1), pty = "s")
qqplot(lm_app, Y_app, xlim = xylim, ylim = xylim, main = "QQ-plot")
abline(b = 1, a = 0, col = "red")
qqplot(lm_test, Y_test, xlim = xylim, ylim = xylim, main = "QQ-plot")
abline(b = 1, a = 0, col = "red")
```

#### analogues / nearest-neighbour

Appliquer la descente d'échelle par analogue.

Pour cela, il faut calculer la distance entre les valeurs de X de la base d'apprentissage et les valeurs de X pour les quelles on souhaite prédire la valeur en Y.

fonction utile: *which.min*

Réaliser les mêmes diagnostics que pour le modèle linéaire.

```{r, fig.width = 6, fig.height = 9}

```

### Model Output Statistic

#### simple mean correction

Appliquer la descente d'échelle par correction de la moyenne.
Réaliser les mêmes dignostics que pour le modèles linéaires.

```{r, fig.width = 6, fig.height = 9}

```

#### quantile-quantile correction

Appliquer la descente d'échelle via la correction quantile quantile.

Fonctions utiles: *ecdf*, *quantile*

Réaliser les mêmes diagnostics que pour le modèles linéaires.

```{r, fig.width = 6, fig.height = 9}

```

### Summary plots
#### Apprentissage
Quelle est la méthode le plus performante sur la base d'apprentissage ?
```{r, fig.width = 6, fig.height = 9}
# Point by point
par(pty = "s")
plot(X_app, Y_app, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5)
points(lm_app, Y_app, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, col = 2)
points(nn_app, Y_app, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, col = 3)
points(mc_app, Y_app, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, col = 4)
points(qq_app, Y_app, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, col = 5)
abline(b = 1, a = 0, col = "red")
legend(
  "topleft",
  legend = c("X", "lm", "nn", "mc", "qq"),
  col = 1:5,
  pch = 20
)
par(pty = "s") 
ylim <- range(c(X_app, lm_app, nn_app, mc_app, qq_app) -  Y_app)
plot(X_app - Y_app, ylim = ylim, type = "l")
lines(lm_app - Y_app, ylim = ylim, col = 2)
lines(nn_app - Y_app, ylim = ylim, col = 3)
lines(mc_app - Y_app, ylim = ylim, col = 4)
lines(qq_app - Y_app, ylim = ylim, col = 5)
abline(h = 0, col = "red")
legend(
  "topleft",
  legend = c("X", "lm", "nn", "mc", "qq"),
  col = 1:5,
  pch = 20
)
# distribution
qqplot_lm <- qqplot(lm_app, Y_app, plot.it = FALSE)
qqplot_nn <- qqplot(nn_app, Y_app, plot.it = FALSE)
qqplot_mc <- qqplot(mc_app, Y_app, plot.it = FALSE)
qqplot_qq <- qqplot(qq_app, Y_app, plot.it = FALSE)
par(pty = "s")
qqplot(X_app, Y_app, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, main = "QQ-plot")
points(qqplot_lm$x, qqplot_lm$y, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, col = 2)
points(qqplot_nn$x, qqplot_nn$y, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, col = 3)
points(qqplot_mc$x, qqplot_mc$y, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, col = 4)
points(qqplot_qq$x, qqplot_qq$y, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, col = 5)
abline(b = 1, a = 0, col = "red")
legend(
  "topleft",
  legend = c("X", "lm", "nn", "mc", "qq"),
  col = 1:5,
  pch = 20
)

# test d'égalité des distribution (à développer si il y a le temps).
ks.test(X_app, Y_app)
ks.test(lm_app, Y_app)
ks.test(nn_app, Y_app)
ks.test(mc_app, Y_app)
ks.test(qq_app, Y_app)
```

#### Test
Quelle est la méthode le plus performante sur la base de test ?

```{r, fig.width = 6, fig.height = 9}

```

## Bias Corretion: only MOS
#### Lecture des données
```{r}
X <- tas_df[, "IPSL-CM5A-LR_historical_r1i1p1"]
Y <- tas_df[, "GHCND_orly"]
ina <- is.na(X) | is.na(Y)
X <- X[!ina]
Y <- Y[!ina]
dates <- as.numeric(rownames(tas_df))
dates <- dates[!ina]
```


### Séparation en base d'apprentissage et base de test (calibration/validation)
```{r}
iapp <- dates < 20000101
X_app <- X[iapp]
Y_app <- Y[iapp]
X_test <- X[!iapp]
Y_test <- Y[!iapp]
```

### Comparaison entre X et Y
```{r, fig.width = 6, fig.height = 9}

```

### Model Output Statistic

#### simple mean correction

Réaliser une correction de bias via la méthode de correction de la moyenne.

```{r, fig.width = 6, fig.height = 9}


```

#### quantile-quantile correction

Réaliser une correction de bias via la méthode quantile quantile.

```{r, fig.width = 6, fig.height = 9}

```

### Summary plots
#### Apprentissage
Quelle est la méthode le plus performante sur la base d'apprentissage ?

```{r, fig.width = 6, fig.height = 9}

```

#### Test
Quelle est la méthode le plus performante sur la base de test ?

```{r, fig.width = 6, fig.height = 9}

```


## Perfect Prognosis: Appliquer le downscaling appris sur les réanalyses aux simulations climatiques.

Est-ce raisonnable ?

```{r, fig.width = 6, fig.height = 9}
# X: IPSL-CM5A-LR_historical_r1i1p1, Y:GHCND_orly
base_gcm <- data.frame(X = X_test, Y = Y_test)
lm_gcm <- predict(lm_fit, newdata = base_gcm)
nn_gcm <- numeric(length(Y_test))
for(i in seq_along(nn_test)){
  dist <- (base_app$X - X_test[i])^2
  inn <- which.min(dist)
  nn_gcm[i] <- base_app$Y[inn]
}
```

### Summary plots
#### base de test
```{r, fig.width = 6, fig.height = 9}
# A ne pas mettre
# distribution
qqplot_lm <- qqplot(lm_gcm, Y_test, plot.it = FALSE)
qqplot_nn <- qqplot(nn_gcm, Y_test, plot.it = FALSE)
par(pty = "s")
qqplot(X_test, Y_test, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, main = "QQ-plot")
points(qqplot_mc$x, qqplot_mc$y, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, col = 4)
points(qqplot_qq$x, qqplot_qq$y, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, col = 5)
points(qqplot_lm$x, qqplot_lm$y, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, col = 2)
points(qqplot_nn$x, qqplot_nn$y, xlim = xylim, ylim = xylim, pch = 20, cex = 0.5, col = 3)
abline(b = 1, a = 0, col = "red")
legend(
  "topleft",
  legend = c("X", "lm", "nn", "mc", "qq"),
  col = 1:5,
  pch = 20
)
ks.test(X_test, Y_test)
ks.test(lm_test, Y_test)
ks.test(nn_test, Y_test)
``` 
## Quelles améliorations pouvez-vous proposer pour améliorer les performances en downscaling ou en correction de biais ?